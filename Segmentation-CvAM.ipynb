{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h6kgTMGcqHRE"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+Ix0FPwBO5EsoL6qoiwk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithuls/MultiviewSegmentation-CvAM/blob/main/Segmentation-CvAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggI-owBMOnWU",
        "outputId": "f98f6eee-4fc7-4b98-fdbb-745921498e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, cv2\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, concatenate, \\\n",
        "              Conv2D, Add, MaxPooling2D, Activation, add, \\\n",
        "              Conv2DTranspose, BatchNormalization, Reshape, \\\n",
        "              GlobalAveragePooling2D, Multiply, Dense, \\\n",
        "              Permute, Multiply, Lambda, concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "#from data import load_train_data, load_test_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "K.set_image_data_format('channels_last')\n",
        "from scipy.spatial.distance import directed_hausdorff"
      ],
      "metadata": {
        "id": "RtcSaUf1O2Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flCn_uyvO8SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Configuration\n",
        "\n",
        "train_full_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-train-full\"\n",
        "train_mask_combined_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-train-mask-combined\"\n",
        "test_full_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-test-full\"\n",
        "test_mask_combined_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-test-mask-combined\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = 224\n",
        "\n",
        "brightness_delta = 0.3\n",
        "\n",
        "batch_size = 8\n",
        "smooth = 1.\n",
        "\n",
        "encoder_input_shape = (target_size, target_size, 3)\n",
        "decoder_kernel_size = (3, 3)\n",
        "decoder_strides = (2, 2)\n",
        "decoder_padding = 'same'\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "1ttaIEJaO8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2srHlsjPO7_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing of Multi-View Images**"
      ],
      "metadata": {
        "id": "5uWGNtzH3B2L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7AP-qAjpvWs"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir, extension):\n",
        "\n",
        "    \"\"\"\n",
        "    Follows the flow:\n",
        "    1.         datasetPaths() *\n",
        "              _______|_______\n",
        "            |               |\n",
        "    2. loadFullImg()  loadMaskImg()\n",
        "            |_______________|\n",
        "                    |\n",
        "    3.          tfParse()\n",
        "                    |\n",
        "    4.         imgAugment()\n",
        "                    |\n",
        "    5.        makeTFDataset()\n",
        "    Takes in the directories of the folder containing the full mammogram\n",
        "    scans (x) and the ground truth masks (y) and returns a list of paths to\n",
        "    individual full scans and masks.\n",
        "    Parameters\n",
        "    ----------\n",
        "    full_img_dir : {str}\n",
        "        Directory that contains the FULL training images.\n",
        "    mask_img_dir : {str}\n",
        "        Directory that contains the MASK training images.\n",
        "    extension : {str}\n",
        "        The file extension of the images (e.g. \".png\")\n",
        "    Returns\n",
        "    -------\n",
        "    x_paths_list: {list}\n",
        "        A list of paths to individual FULL images in the training set.\n",
        "    y_paths_list: {list}\n",
        "        A list of paths to individual MASK images in the training set.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # =======================================\n",
        "        #  1. Get paths of X (full) and y (mask)\n",
        "        # =======================================\n",
        "\n",
        "        x_paths_list = []\n",
        "        y_paths_list = []\n",
        "\n",
        "        full_img_ID = [fn[:26] for fn in sorted(os.listdir(full_img_dir))]\n",
        "        mask_img_ID = [fn[:26] for fn in sorted(os.listdir(mask_img_dir))]\n",
        "\n",
        "        full_dirs = [fn for fn in sorted(os.listdir(full_img_dir))]\n",
        "        mask_dirs = [fn for fn in sorted(os.listdir(mask_img_dir))]\n",
        "\n",
        "        ## Common Elements\n",
        "        common_ID_FullandMask = []\n",
        "        temp_mask_img_ID = mask_img_ID\n",
        "        for a_ in full_img_ID:\n",
        "          for b_ in temp_mask_img_ID:\n",
        "            if a_ == b_:\n",
        "              common_ID_FullandMask.append(a_)\n",
        "              temp_mask_img_ID.remove(b_)\n",
        "\n",
        "        temp_full_path, temp_mask_path = 0, 0 ## For checking if the 'Below function ifs' are picking anything\n",
        "\n",
        "        for i in range(len(common_ID_FullandMask)):\n",
        "            for j in range(len(full_dirs)):\n",
        "                fn_ = full_dirs[j]\n",
        "                if common_ID_FullandMask[i] in fn_ and fn_.endswith(extension):\n",
        "                    temp_full_path = fn_\n",
        "                    break\n",
        "            for k in range(len(mask_dirs)):\n",
        "                fn_2 = mask_dirs[k]\n",
        "                if common_ID_FullandMask[i] in fn_2 and fn_2.endswith(extension) :\n",
        "                    temp_mask_path = fn_2\n",
        "                    break\n",
        "            if temp_full_path == 0 or temp_mask_path == 0:\n",
        "                temp_full_path, temp_mask_path = 0, 0\n",
        "                continue\n",
        "            \n",
        "            full_dirs.pop(j)\n",
        "            mask_dirs.pop(k)\n",
        "            x_paths_list.append(os.path.join(full_img_dir, temp_full_path))\n",
        "            y_paths_list.append(os.path.join(mask_img_dir, temp_mask_path))\n",
        "\n",
        "            temp_full_path, temp_mask_path = 0, 0 # Reasserting value to 0\n",
        "\n",
        "\n",
        "        print('x_paths_list length', len(x_paths_list))\n",
        "        print('y_paths_list length', len(y_paths_list))\n",
        "\n",
        "\n",
        "        # Get paths of train images and masks.\n",
        "        '''for full in os.listdir(full_img_dir):\n",
        "            if full.endswith(extension):\n",
        "                x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "\n",
        "        for mask in os.listdir(mask_img_dir):\n",
        "            if mask.endswith(extension):\n",
        "                y_paths_list.append(os.path.join(mask_img_dir, mask))'''\n",
        "\n",
        "        # ** IMPORTANT ** Sort so that FULL and MASK images are in an order\n",
        "        # that corresponds with each other.\n",
        "        #x_paths_list.sort()\n",
        "        #y_paths_list.sort()\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to datasetPaths!\\n{e}')\n",
        "        print((f\"Unable to datasetPaths!\\n{e}\"))\n",
        "\n",
        "    return x_paths_list, y_paths_list\n",
        "\n",
        "\n",
        "def create_dict(full_dir, mask_combined_dir):\n",
        "    full_img_files = sorted(os.listdir(full_dir))\n",
        "    mask_img_files = sorted(os.listdir(mask_combined_dir))\n",
        "\n",
        "    if \"train\" in full_dir:\n",
        "        str_start, str_end = 16, 27\n",
        "    elif \"test\" in full_dir:\n",
        "        str_start, str_end = 12, 23\n",
        "\n",
        "    hm_files = {}\n",
        "    for f1, f2 in zip(full_img_files, mask_img_files):\n",
        "        temp_key = f1[str_start : str_end]    ## Key is the patient id and left/right breast\n",
        "        if temp_key not in hm_files:\n",
        "            hm_files[temp_key] = [[], []]\n",
        "        hm_files[temp_key][0].append(os.path.join(full_dir, f1))\n",
        "        hm_files[temp_key][1].append(os.path.join(mask_combined_dir, f2))\n",
        "\n",
        "    # for key in hm_files:\n",
        "    #     print(key, hm_files[key])\n",
        "\n",
        "    count = 0\n",
        "    keys_to_pop = []\n",
        "    for key in hm_files:\n",
        "        if len(hm_files[key][0]) == 1:\n",
        "            keys_to_pop.append(key)\n",
        "            count += 1\n",
        "\n",
        "    print(\"Before popping, number of keys to pop with length 1: \", count, \" and total length: \", len(hm_files.keys()))\n",
        "\n",
        "    for key in keys_to_pop:\n",
        "        hm_files.pop(key, None)\n",
        "\n",
        "    ## To check if the dictionary has any key with length 1\n",
        "    count = 0\n",
        "    for key in hm_files:\n",
        "        if len(hm_files[key][0]) == 1:\n",
        "            count += 1\n",
        "            # print(key)\n",
        "\n",
        "    print(\"After popping, number of keys to pop with length 1: \", count)\n",
        "    print(\"After popping, number of keys with length 2: \", len(hm_files.keys()))\n",
        "\n",
        "    return hm_files\n",
        "\n",
        "def loadFullImg(path, dsize):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in the path of a FULL image and loads it as a grayscale image (as\n",
        "    a numpy array with 3 channels).\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : {str}\n",
        "        The path of the FULL image.\n",
        "    Returns\n",
        "    -------\n",
        "    full_img : {numpy.ndarray}\n",
        "        The loaded image with shape = (self.target_size, self.target_size, 3)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # =====================================\n",
        "        #  2a. Read images (full)\n",
        "        # =====================================\n",
        "        # if not isinstance(path, str):\n",
        "        #     path = path.decode()\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(src=img, dsize=(dsize, dsize))\n",
        "\n",
        "        # Min max normalise to [0, 1].\n",
        "        norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "        # Stack grayscale image to make channels=3.\n",
        "        full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to loadFullImg!\\n{e}')\n",
        "        print((f\"Unable to loadFullImg!\\n{e}\"))\n",
        "\n",
        "    return full_img\n",
        "\n",
        "def loadMaskImg(path, dsize):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in the path of a MASK image and loads it as a grayscale image (as\n",
        "    a numpy array with 1 channel).\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : {str}\n",
        "        The path of the MASK image.\n",
        "    Returns\n",
        "    -------\n",
        "    full_img : {numpy.ndarray}\n",
        "        The loaded image with shape = (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # ========================\n",
        "        #  2b. Read images (mask)\n",
        "        # ========================\n",
        "        # if not isinstance(path, str):\n",
        "        #     path = path.decode()\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(src=img, dsize=(dsize,dsize))\n",
        "\n",
        "        # Min max normalise to [0, 1].\n",
        "        norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "        # Expand shape to (width, height, 1).\n",
        "        mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to loadMaskImg!\\n{e}')\n",
        "        print((f\"Unable to loadMaskImg!\\n{e}\"))\n",
        "\n",
        "    return mask_img\n",
        "\n",
        "def tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in a FULL image path and a MASK image path, loads the images using\n",
        "    loadFullImg() and loadMaskImg() and makes it TensorFlow executable.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x_path: {str}\n",
        "        The path of the FULL image to be loaded.\n",
        "    y_path: {str}\n",
        "        The path of the MASK image to be loaded.\n",
        "    Returns\n",
        "    -------\n",
        "    x : {tensor}\n",
        "        The FULL image loaded as a tensor with shape =\n",
        "        (self.target_size, self.target_size, 3)\n",
        "    y : {tensor}\n",
        "        The MASK image loaded as a tensor with shape =\n",
        "        (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def _parse(x_path, y_path):\n",
        "        x = loadFullImg(path=x_path, dsize=target_size)\n",
        "        y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "        return x, y\n",
        "\n",
        "    try:\n",
        "        # ===========\n",
        "        #  3. Parse\n",
        "        # ===========\n",
        "\n",
        "        # x_cc, y_cc = tf.numpy_function(_parse, [img_cc_path, mask_cc_path], [tf.float64, tf.float64])\n",
        "        # x_mlo, y_mlo = tf.numpy_function(_parse, [img_mlo_path, mask_mlo_path], [tf.float64, tf.float64])\n",
        "\n",
        "        x_cc, y_cc = _parse(img_cc_path, mask_cc_path)\n",
        "        x_mlo, y_mlo = _parse(img_mlo_path, mask_mlo_path)\n",
        "\n",
        "        print(np.shape(x_cc), np.shape(y_cc))\n",
        "\n",
        "        # x_cc.set_shape([target_size, target_size, 3])\n",
        "        # x_mlo.set_shape([target_size, target_size, 3])\n",
        "        # y_cc.set_shape([target_size, target_size, 1])\n",
        "        # y_mlo.set_shape([target_size, target_size, 1])\n",
        "\n",
        "        x = concatenate([x_cc, x_mlo], axis = -1)\n",
        "        y = concatenate([y_cc, y_mlo], axis = -1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to tfParse!\\n{e}')\n",
        "        print((f\"Unable to tfParse!\\n{e}\"))\n",
        "\n",
        "def imgAugment(x_img, y_img):\n",
        "\n",
        "    \"\"\"\n",
        "    Apply random image augmentation to full mammogram scans (x_img). Note\n",
        "    that the same augmentation has to be applied to the masks (y_img), apart\n",
        "    from the brightness augmentation.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x_img : {numpy.ndarray}\n",
        "        Full mammogram scan to augment.\n",
        "    y_img : {numpy.ndarray}\n",
        "        Corresponding mask of `x_img`.\n",
        "    Returns\n",
        "    -------\n",
        "    x_img : {numpy.ndarray}\n",
        "        Augmented x_img.\n",
        "    y_img : {numpy.ndarray}\n",
        "        Augmented y_img.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # =========\n",
        "        #  LR Flip\n",
        "        # =========\n",
        "        # Generate random number from uniform distribution\n",
        "        # in the range [0.0, 1.0)\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            x_img = tf.image.flip_left_right(image=x_img)\n",
        "            y_img = tf.image.flip_left_right(image=y_img)\n",
        "\n",
        "        # =========\n",
        "        #  UD Flip\n",
        "        # =========\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            x_img = tf.image.flip_up_down(image=x_img)\n",
        "            y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "        # ============\n",
        "        #  Brightness\n",
        "        # ============\n",
        "        # Only change the brightness of x_img, not y_img!\n",
        "        x_img = tf.image.random_brightness(\n",
        "            image=x_img, max_delta= brightness_delta\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to imgAugment!\\n{e}')\n",
        "        print((f\"Unable to imgAugment!\\n{e}\"))\n",
        "\n",
        "    return x_img, y_img\n",
        "\n",
        "def makeTFDataset(shuffle, augment, x_paths_list, y_paths_list, batch_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in a FULL image path and a MASK image path, loads the images using\n",
        "    loadFullImg() and loadMaskImg() and makes it TensorFlow executable.\n",
        "    Parameters\n",
        "    ----------\n",
        "    shuffle : {boolean}\n",
        "        If True, shuffle dataset. Should only shuffle train set.\n",
        "    augment : {boolean}\n",
        "        If True, perform augmentation. Should only augment test set.\n",
        "    x_paths_list : {list}\n",
        "        The path of the FULL image to be loaded.\n",
        "    y_paths_list : {list}\n",
        "        The path of the MASK image to be loaded.\n",
        "    batch_size : {int}\n",
        "        The batch size to create the dataset with.\n",
        "    Returns\n",
        "    -------\n",
        "    ds : {RepeatDataset}\n",
        "        The dataset with x (FULL) and y (MASK) images loaded from\n",
        "        `x_paths_list` and `y_paths_list`.\n",
        "        For each `batch` in `ds`:\n",
        "        - type = tuple\n",
        "        - len = 2\n",
        "        - `batch[0]` (this is a batch of the FULL images):\n",
        "            - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "            - shape = (self.batch_size, self.target_size, self.target_size, 3)\n",
        "            - `batch[0][0]` (this is the first FULL image in the batch):\n",
        "                - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "                - shape = (self.target_size, self.target_size, 3)\n",
        "        - `batch[1]` (this is a batch the MASK images):\n",
        "            - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "            - shape = (self.batch_size, self.target_size, self.target_size, 1)\n",
        "                - `batch[1][0]` (this is the first MASK image in the batch):\n",
        "                - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "                - shape = (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # ====================\n",
        "        #  4. Make TF Dataset\n",
        "        # ====================\n",
        "\n",
        "        ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "\n",
        "        # Shuffle the paths of the elements\n",
        "        # with buffer_size=len(x_paths_list), since storing all the paths\n",
        "        # in memory will not be an issue (as compared to storing all the\n",
        "        # imported images as tensors).\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "        # Transform paths to images after shuffling the paths.\n",
        "        ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        # Apply image augmentation.\n",
        "        if augment:\n",
        "            ds = ds.map(\n",
        "                imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "            )\n",
        "\n",
        "        # Batch only AFTER shuffle, so that we shuffled the elements not the batches.\n",
        "        ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "        ds = ds.repeat()  # We need to repeat in order to train for > 1 epoch.\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to makeTFDataset!\\n{e}')\n",
        "        print((f\"Unable to makeTFDataset!\\n{e}\"))\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hm_train_files_multi_view = create_dict(train_full_dir, train_mask_combined_dir)\n",
        "hm_test_files_multi_view = create_dict(test_full_dir, test_mask_combined_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd5QpS-lj1-s",
        "outputId": "6613db70-127f-4125-be9d-eabc636a66c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before popping, number of keys to pop with length 1:  213  and total length:  722\n",
            "After popping, number of keys to pop with length 1:  0\n",
            "After popping, number of keys with length 2:  509\n",
            "Before popping, number of keys to pop with length 1:  59  and total length:  211\n",
            "After popping, number of keys to pop with length 1:  0\n",
            "After popping, number of keys with length 2:  152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = [], []\n",
        "\n",
        "for key in hm_train_files_multi_view:\n",
        "    img_cc_path, img_mlo_path = sorted(hm_train_files_multi_view[key][0])\n",
        "    mask_cc_path, mask_mlo_path = sorted(hm_train_files_multi_view[key][1])\n",
        "\n",
        "    x, y = tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path)\n",
        "    X_train.append(x)\n",
        "    y_train.append(y)"
      ],
      "metadata": {
        "id": "M-WDWdA4kPxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = [], []\n",
        "\n",
        "for key in hm_test_files_multi_view:\n",
        "    img_cc_path, img_mlo_path = sorted(hm_test_files_multi_view[key][0])\n",
        "    mask_cc_path, mask_mlo_path = sorted(hm_test_files_multi_view[key][1])\n",
        "\n",
        "    x, y = tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path)\n",
        "    X_test.append(x)\n",
        "    y_test.append(y)"
      ],
      "metadata": {
        "id": "CjhfpsiHwesE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxfSTtLSwepc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_cc = X_test[0][ :, :, : 3]\n",
        "input_mlo = X_test[0][ :, :, 3 :]"
      ],
      "metadata": {
        "id": "Ro8UiaTp1q2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(input_cc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV5k5QLo1qza",
        "outputId": "04df1c4a-2f74-423b-cf74-ce11c0b9eaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in hm_test_files_multi_view:\n",
        "    img_cc_path, img_mlo_path = sorted(hm_test_files_multi_view[key][0])\n",
        "    mask_cc_path, mask_mlo_path = sorted(hm_test_files_multi_view[key][1])\n",
        "\n",
        "    x, y = tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBCo4XkG1zn4",
        "outputId": "e696c724-2900-4533-ed91-f623fc5e787a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3) (224, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x[:, :, : 3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWFRQKZY1zgJ",
        "outputId": "7600f4c9-fb7d-44e1-befb-3e1760d695ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(y_train[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8k7YIPm3Ibt",
        "outputId": "ae6ae9c4-fb13-4748-b08b-c213ad0eb036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([224, 224, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6kgTMGcqHRE"
      },
      "source": [
        "## **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP-NZHkzqGSE"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    \n",
        "def dice(pred, true, k = 1):\n",
        "    intersection = np.sum(pred[true==k]) * 2.0\n",
        "    dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "    return dice\n",
        "\n",
        "def iou(pred, true, k = 1):\n",
        "    intersection = np.sum(pred[true==k])\n",
        "    iou = intersection / (np.sum(pred) + np.sum(true) - intersection)\n",
        "    return iou\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def sens(y_true, y_pred):\n",
        "    num=K.sum(K.multiply(y_true, y_pred))\n",
        "    denom=K.sum(y_true)\n",
        "    if denom==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return  num/denom\n",
        "\n",
        "def spec(y_true, y_pred):\n",
        "    num=K.sum(K.multiply(y_true==0, y_pred==0))\n",
        "    denom=K.sum(y_true==0)\n",
        "    if denom==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return  num/denom\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "\n",
        "## From TDS guy\n",
        "\n",
        "def iouMetric(y_true, y_pred):\n",
        "\n",
        "      \"\"\"\n",
        "      Calculates the intersection-over-union between a ground truth mask and\n",
        "      the corresponding predicted mask from the model.\n",
        "      Parameters\n",
        "      ----------\n",
        "      y_true : {tf.Tensor}\n",
        "          The ground truth mask.\n",
        "      y_pred : {tf.Tensor}\n",
        "          Corresponding predicted mask.\n",
        "      Returns\n",
        "      -------\n",
        "      compute_iou() : {tf.numpy_function}\n",
        "          A function that calculates the IOU metric.\n",
        "      \"\"\"\n",
        "\n",
        "      try:\n",
        "\n",
        "          def compute_iou(y_true, y_pred):\n",
        "              intersection = (y_true * y_pred).sum()\n",
        "              union = y_true.sum() + y_pred.sum() - intersection\n",
        "              x = (intersection + 1e-15) / (union + 1e-15)\n",
        "              x = x.astype(np.float32)\n",
        "              return x\n",
        "\n",
        "          return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "\n",
        "      except Exception as e:\n",
        "          # logger.error(f'Unable to iouMetric!\\n{e}')\n",
        "          print((f\"Unable to iouMetric!\\n{e}\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsqvnOJB3IWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8driqnr2Eo5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CvAM with Basic U-Net**"
      ],
      "metadata": {
        "id": "-hRwWO5K43vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cvam_spatial_attention(x_cc,x_mlo):\n",
        "    avg_pool_cc = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(x_cc)\n",
        "    assert avg_pool_cc.shape[-1] == 1\n",
        "    max_pool_cc = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(x_cc)\n",
        "    assert max_pool_cc.shape[-1] == 1\n",
        "\n",
        "    avg_pool_mlo = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(x_mlo)\n",
        "    assert avg_pool_mlo.shape[-1] == 1\n",
        "    max_pool_mlo = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(x_mlo)\n",
        "    assert max_pool_mlo.shape[-1] == 1\n",
        "\n",
        "    concat = concatenate(axis=3)([avg_pool_cc, max_pool_cc, avg_pool_mlo, max_pool_mlo])\n",
        "    assert concat.shape[-1] == 4\n",
        "    cvam_feature = Conv2D(4, (3, 3), padding=\"same\")(concat)\n",
        "    cvam_feature = Activation('relu')(cvam_feature)\n",
        "    cvam_feature = Conv2D(1, (3, 3), padding=\"same\")(cvam_feature)\n",
        "    cvam_feature = Activation('sigmoid')(cvam_feature)\n",
        "    #print (cvam_feature)\n",
        "    assert cvam_feature.shape[-1] == 1\n",
        "    # if K.image_data_format() == \"channels_first\":\n",
        "    #   cvam_feature = Permute((3, 1, 2))(cvam_feature)\n",
        "\n",
        "    # print (multiply([x, cvam_feature]))\n",
        "    # return multiply([x, cvam_feature])\n",
        "\n",
        "    print(Multiply([x_cc, cvam_feature]))\n",
        "    print(Multiply([x_mlo, cvam_feature]))\n",
        "\n",
        "    cvam_cc, cvam_mlo = Multiply([x_cc, cvam_feature]), Multiply([x_mlo, cvam_feature])\n",
        "    return cvam_cc, cvam_mlo"
      ],
      "metadata": {
        "id": "OBI4x7aj43Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3yG4h2AsUbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_with_cvam():\n",
        "    inputs = Input((target_size, target_size, 6))\n",
        "\n",
        "    ## Splitting the inputs into cc and mlo\n",
        "\n",
        "    input_cc = inputs[:, :, :, : 3]\n",
        "    input_mlo = inputs[:, :, :, 3 :]\n",
        "\n",
        "    ## 1st Layer\n",
        "\n",
        "    conv1_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(input_cc)\n",
        "    conv1_cc = BatchNormalization()(conv1_cc)\n",
        "    conv1_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1_cc)\n",
        "    conv1_cc = BatchNormalization()(conv1_cc)\n",
        "    pool1_cc = MaxPooling2D((2,2), padding='same')(conv1_cc)\n",
        "\n",
        "    print(np.shape(pool1_cc))\n",
        "\n",
        "    conv1_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(input_mlo)\n",
        "    conv1_mlo = BatchNormalization()(conv1_mlo)\n",
        "    conv1_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1_mlo)\n",
        "    conv1_mlo = BatchNormalization()(conv1_mlo)\n",
        "    pool1_mlo = MaxPooling2D((2,2), padding='same')(conv1_mlo)\n",
        "\n",
        "    ## 2nd Layer\n",
        "\n",
        "    conv2_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1_cc)\n",
        "    conv2_cc = BatchNormalization()(conv2_cc)\n",
        "    conv2_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2_cc)\n",
        "    conv2_cc = BatchNormalization()(conv2_cc)\n",
        "    pool2_cc = MaxPooling2D((2,2), padding='same')(conv2_cc)\n",
        "\n",
        "    print(np.shape(pool2_cc))\n",
        "\n",
        "    conv2_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1_mlo)\n",
        "    conv2_mlo = BatchNormalization()(conv2_mlo)\n",
        "    conv2_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2_mlo)\n",
        "    conv2_mlo = BatchNormalization()(conv2_mlo)\n",
        "    pool2_mlo = MaxPooling2D((2,2), padding='same')(conv2_mlo)\n",
        "\n",
        "    ## 3rd Layer\n",
        "\n",
        "    conv3_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2_cc)\n",
        "    conv3_cc = BatchNormalization()(conv3_cc)\n",
        "    conv3_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3_cc)\n",
        "    conv3_cc = BatchNormalization()(conv3_cc)\n",
        "    pool3_cc = MaxPooling2D((2,2), padding='same')(conv3_cc)\n",
        "\n",
        "    conv3_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2_mlo)\n",
        "    conv3_mlo = BatchNormalization()(conv3_mlo)\n",
        "    conv3_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3_mlo)\n",
        "    conv3_mlo = BatchNormalization()(conv3_mlo)\n",
        "    pool3_mlo = MaxPooling2D((2,2), padding='same')(conv3_mlo)\n",
        "\n",
        "\n",
        "    ## 4th Layer\n",
        "\n",
        "    conv4_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3_cc)\n",
        "    conv4_cc = BatchNormalization()(conv4_cc)\n",
        "    conv4_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4_cc)\n",
        "    conv4_cc = BatchNormalization()(conv4_cc)\n",
        "    pool4_cc = MaxPooling2D((2,2), padding='same')(conv4_cc)\n",
        "\n",
        "    conv4_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3_mlo)\n",
        "    conv4_mlo = BatchNormalization()(conv4_mlo)\n",
        "    conv4_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4_mlo)\n",
        "    conv4_mlo = BatchNormalization()(conv4_mlo)\n",
        "    pool4_mlo = MaxPooling2D((2,2), padding='same')(conv4_mlo)\n",
        "\n",
        "    ## 5th Layer\n",
        "\n",
        "    conv5_cc = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4_cc)\n",
        "    conv5_cc = BatchNormalization()(conv5_cc)\n",
        "    conv5_cc = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_cc)\n",
        "    conv5_cc = BatchNormalization()(conv5_cc)\n",
        "\n",
        "    conv5_mlo = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4_mlo)\n",
        "    conv5_mlo = BatchNormalization()(conv5_mlo)\n",
        "    conv5_mlo = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_mlo)\n",
        "    conv5_mlo = BatchNormalization()(conv5_mlo)\n",
        "\n",
        "    ## 6th Layer\n",
        "\n",
        "    up6_cc = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5_cc), conv4_cc], axis=3)\n",
        "    conv6_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(up6_cc)\n",
        "    conv6_cc = BatchNormalization()(conv6_cc)\n",
        "    conv6_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6_cc)\n",
        "    conv6_cc = BatchNormalization()(conv6_cc)\n",
        "\n",
        "    up6_mlo = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5_mlo), conv4_mlo], axis=3)\n",
        "    conv6_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(up6_mlo)\n",
        "    conv6_mlo = BatchNormalization()(conv6_mlo)\n",
        "    conv6_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6_mlo)\n",
        "    conv6_mlo = BatchNormalization()(conv6_mlo)\n",
        "\n",
        "    ## 7th Layer\n",
        "    \n",
        "    up7_cc = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6_cc), conv3_cc], axis=3)\n",
        "    conv7_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(up7_cc)\n",
        "    conv7_cc = BatchNormalization()(conv7_cc)\n",
        "    conv7_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7_cc)\n",
        "    conv7_cc = BatchNormalization()(conv7_cc)\n",
        "\n",
        "    up7_mlo = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6_mlo), conv3_mlo], axis=3)\n",
        "    conv7_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(up7_mlo)\n",
        "    conv7_mlo = BatchNormalization()(conv7_mlo)\n",
        "    conv7_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7_mlo)\n",
        "    conv7_mlo = BatchNormalization()(conv7_mlo)\n",
        "\n",
        "    ## 8th Layer\n",
        "\n",
        "    up8_cc = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7_cc), conv2_cc], axis=3)\n",
        "    conv8_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(up8_cc)\n",
        "    conv8_cc = BatchNormalization()(conv8_cc)\n",
        "    conv8_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8_cc)\n",
        "    conv8_cc = BatchNormalization()(conv8_cc)\n",
        "\n",
        "    up8_mlo = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7_mlo), conv2_mlo], axis=3)\n",
        "    conv8_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(up8_mlo)\n",
        "    conv8_mlo = BatchNormalization()(conv8_mlo)\n",
        "    conv8_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8_mlo)\n",
        "    conv8_mlo = BatchNormalization()(conv8_mlo)\n",
        "\n",
        "    ## 9th Layer\n",
        "    \n",
        "    up9_cc = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8_cc), conv1_cc], axis=3)\n",
        "    conv9_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(up9_cc)\n",
        "    conv9_cc = BatchNormalization()(conv9_cc)\n",
        "    conv9_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9_cc)\n",
        "    conv9_cc = BatchNormalization()(conv9_cc)\n",
        "\n",
        "    up9_mlo = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8_mlo), conv1_mlo], axis=3)\n",
        "    conv9_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(up9_mlo)\n",
        "    conv9_mlo = BatchNormalization()(conv9_mlo)\n",
        "    conv9_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9_mlo)\n",
        "    conv9_mlo = BatchNormalization()(conv9_mlo)\n",
        "\n",
        "    ## Final Layer\n",
        "        \n",
        "    conv10_cc = Conv2D(1, (1, 1), activation='sigmoid')(conv9_cc)\n",
        "    conv10_mlo = Conv2D(1, (1, 1), activation='sigmoid')(conv9_mlo)\n",
        "\n",
        "    ## Stacking the final masks on top of another\n",
        "    conv10 = concatenate([conv10_cc, conv10_mlo], axis= -1)\n",
        "\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "    model.compile(optimizer = Adam(1e-3), loss = 'binary_crossentropy', metrics = [dice_coef, jacard, 'accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "yBKG_rMUsUYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVBY3skUsUVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_cvam = unet_with_cvam()"
      ],
      "metadata": {
        "id": "eqBG93mFTUQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_cvam.fit(X_train, y_train,\n",
        "                    validation_split = 0.2,\n",
        "                    epochs=300,\n",
        "                    batch_size = 8,\n",
        "                    # steps_per_epoch=train_steps,\n",
        "                    # validation_steps=val_steps,\n",
        "                    # callbacks=[model_checkpoint, reduce_lr, early_S],\n",
        "                    verbose=1,\n",
        "                )   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "ddisOmMswwwi",
        "outputId": "262bce52-ef93-4329-a99f-57883d81bc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c63e3e4adc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;31m# validation_steps=val_steps,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;31m# callbacks=[model_checkpoint, reduce_lr, early_S],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 )   \n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_1\" expects 1 input(s), but it received 509 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:5' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:7' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:8' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:9' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:10' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:11' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:12' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:13' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:14' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:15' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:16' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:17' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:18' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGetNext:19' shape=(None, 224, 6) dtype=float32>, <tf.Tensor 'IteratorGe...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaGnHz_hxNR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEZpz24CxNPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHHJjdJowwt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = train_size // batch_size\n",
        "val_steps =  val_size // batch_size\n",
        "test_steps = test_size // batch_size\n",
        "\n",
        "if train_size % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if val_size % batch_size != 0:\n",
        "    val_steps += 1\n",
        "if test_size % batch_size != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "\n",
        "\n",
        "#loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
        "#metrics=[dice_coef, jacard, iou_coef, 'accuracy']\n",
        "#loss = modified_loss()\n",
        "#u_net_inbreast.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "fname = \"u_net_inbreast_epoch_{epoch:02d}_-dice_{val_dice_coef:.2f}-iou_{val_jacard:.2f}+395.hdf5\"\n",
        "model_checkpoint = ModelCheckpoint(fname, monitor='val_loss', save_best_only=False)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "early_S = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)\n",
        "\n",
        "print('-'*30)\n",
        "print('Fitting u_net_inbreast...')\n",
        "print('-'*30)\n",
        "\n",
        "history = u_net_inbreast.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=300,\n",
        "                    steps_per_epoch=train_steps,\n",
        "                    validation_steps=val_steps,\n",
        "                    callbacks=[model_checkpoint, reduce_lr, early_S],\n",
        "                    verbose=1,\n",
        "                )   "
      ],
      "metadata": {
        "id": "oyaw2KoPUYgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzOvGpgJ43Tj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}