{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5uWGNtzH3B2L",
        "UgICC641kPk_",
        "a5s7PuM1j-qy",
        "h6kgTMGcqHRE"
      ],
      "authorship_tag": "ABX9TyNydem+ig+eYmdHUDlGbjVw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prithuls/MultiviewSegmentation-CvAM/blob/main/MultiViewUNet_CvAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggI-owBMOnWU",
        "outputId": "39dfb7d4-1621-4ad3-d194-afb4078832ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, cv2\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, concatenate, \\\n",
        "              Conv2D, Add, MaxPooling2D, Activation, add, \\\n",
        "              Conv2DTranspose, BatchNormalization, Reshape, \\\n",
        "              GlobalAveragePooling2D, Multiply, Dense, \\\n",
        "              Permute, Multiply, Lambda, concatenate, \\\n",
        "              GlobalMaxPool2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "#from data import load_train_data, load_test_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "K.set_image_data_format('channels_last')\n",
        "from scipy.spatial.distance import directed_hausdorff"
      ],
      "metadata": {
        "id": "RtcSaUf1O2Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flCn_uyvO8SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Configuration\n",
        "\n",
        "train_full_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-train-full\"\n",
        "train_mask_combined_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-train-mask-combined\"\n",
        "test_full_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-test-full\"\n",
        "test_mask_combined_dir = \"/content/gdrive/MyDrive/CS791MassDetectionOnMammograms/Data(CBIS-DDSM)/processed/mass-test-mask-combined\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = 224\n",
        "\n",
        "brightness_delta = 0.3\n",
        "\n",
        "batch_size = 8\n",
        "smooth = 1.\n",
        "\n",
        "encoder_input_shape = (target_size, target_size, 3)\n",
        "decoder_kernel_size = (3, 3)\n",
        "decoder_strides = (2, 2)\n",
        "decoder_padding = 'same'\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "learning_rate = 0.0001"
      ],
      "metadata": {
        "id": "1ttaIEJaO8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2srHlsjPO7_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "5uWGNtzH3B2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing of Multi-View Images"
      ],
      "metadata": {
        "id": "UgICC641kPk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7AP-qAjpvWs"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir, extension):\n",
        "\n",
        "    \"\"\"\n",
        "    Follows the flow:\n",
        "    1.         datasetPaths() *\n",
        "              _______|_______\n",
        "            |               |\n",
        "    2. loadFullImg()  loadMaskImg()\n",
        "            |_______________|\n",
        "                    |\n",
        "    3.          tfParse()\n",
        "                    |\n",
        "    4.         imgAugment()\n",
        "                    |\n",
        "    5.        makeTFDataset()\n",
        "    Takes in the directories of the folder containing the full mammogram\n",
        "    scans (x) and the ground truth masks (y) and returns a list of paths to\n",
        "    individual full scans and masks.\n",
        "    Parameters\n",
        "    ----------\n",
        "    full_img_dir : {str}\n",
        "        Directory that contains the FULL training images.\n",
        "    mask_img_dir : {str}\n",
        "        Directory that contains the MASK training images.\n",
        "    extension : {str}\n",
        "        The file extension of the images (e.g. \".png\")\n",
        "    Returns\n",
        "    -------\n",
        "    x_paths_list: {list}\n",
        "        A list of paths to individual FULL images in the training set.\n",
        "    y_paths_list: {list}\n",
        "        A list of paths to individual MASK images in the training set.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # =======================================\n",
        "        #  1. Get paths of X (full) and y (mask)\n",
        "        # =======================================\n",
        "\n",
        "        x_paths_list = []\n",
        "        y_paths_list = []\n",
        "\n",
        "        full_img_ID = [fn[:26] for fn in sorted(os.listdir(full_img_dir))]\n",
        "        mask_img_ID = [fn[:26] for fn in sorted(os.listdir(mask_img_dir))]\n",
        "\n",
        "        full_dirs = [fn for fn in sorted(os.listdir(full_img_dir))]\n",
        "        mask_dirs = [fn for fn in sorted(os.listdir(mask_img_dir))]\n",
        "\n",
        "        ## Common Elements\n",
        "        common_ID_FullandMask = []\n",
        "        temp_mask_img_ID = mask_img_ID\n",
        "        for a_ in full_img_ID:\n",
        "          for b_ in temp_mask_img_ID:\n",
        "            if a_ == b_:\n",
        "              common_ID_FullandMask.append(a_)\n",
        "              temp_mask_img_ID.remove(b_)\n",
        "\n",
        "        temp_full_path, temp_mask_path = 0, 0 ## For checking if the 'Below function ifs' are picking anything\n",
        "\n",
        "        for i in range(len(common_ID_FullandMask)):\n",
        "            for j in range(len(full_dirs)):\n",
        "                fn_ = full_dirs[j]\n",
        "                if common_ID_FullandMask[i] in fn_ and fn_.endswith(extension):\n",
        "                    temp_full_path = fn_\n",
        "                    break\n",
        "            for k in range(len(mask_dirs)):\n",
        "                fn_2 = mask_dirs[k]\n",
        "                if common_ID_FullandMask[i] in fn_2 and fn_2.endswith(extension) :\n",
        "                    temp_mask_path = fn_2\n",
        "                    break\n",
        "            if temp_full_path == 0 or temp_mask_path == 0:\n",
        "                temp_full_path, temp_mask_path = 0, 0\n",
        "                continue\n",
        "            \n",
        "            full_dirs.pop(j)\n",
        "            mask_dirs.pop(k)\n",
        "            x_paths_list.append(os.path.join(full_img_dir, temp_full_path))\n",
        "            y_paths_list.append(os.path.join(mask_img_dir, temp_mask_path))\n",
        "\n",
        "            temp_full_path, temp_mask_path = 0, 0 # Reasserting value to 0\n",
        "\n",
        "\n",
        "        print('x_paths_list length', len(x_paths_list))\n",
        "        print('y_paths_list length', len(y_paths_list))\n",
        "\n",
        "\n",
        "        # Get paths of train images and masks.\n",
        "        '''for full in os.listdir(full_img_dir):\n",
        "            if full.endswith(extension):\n",
        "                x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "\n",
        "        for mask in os.listdir(mask_img_dir):\n",
        "            if mask.endswith(extension):\n",
        "                y_paths_list.append(os.path.join(mask_img_dir, mask))'''\n",
        "\n",
        "        # ** IMPORTANT ** Sort so that FULL and MASK images are in an order\n",
        "        # that corresponds with each other.\n",
        "        #x_paths_list.sort()\n",
        "        #y_paths_list.sort()\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to datasetPaths!\\n{e}')\n",
        "        print((f\"Unable to datasetPaths!\\n{e}\"))\n",
        "\n",
        "    return x_paths_list, y_paths_list\n",
        "\n",
        "\n",
        "def create_dict(full_dir, mask_combined_dir):\n",
        "    full_img_files = sorted(os.listdir(full_dir))\n",
        "    mask_img_files = sorted(os.listdir(mask_combined_dir))\n",
        "\n",
        "    if \"train\" in full_dir:\n",
        "        str_start, str_end = 16, 27\n",
        "    elif \"test\" in full_dir:\n",
        "        str_start, str_end = 12, 23\n",
        "\n",
        "    hm_files = {}\n",
        "    for f1, f2 in zip(full_img_files, mask_img_files):\n",
        "        temp_key = f1[str_start : str_end]    ## Key is the patient id and left/right breast\n",
        "        if temp_key not in hm_files:\n",
        "            hm_files[temp_key] = [[], []]\n",
        "        hm_files[temp_key][0].append(os.path.join(full_dir, f1))\n",
        "        hm_files[temp_key][1].append(os.path.join(mask_combined_dir, f2))\n",
        "\n",
        "    # for key in hm_files:\n",
        "    #     print(key, hm_files[key])\n",
        "\n",
        "    count = 0\n",
        "    keys_to_pop = []\n",
        "    for key in hm_files:\n",
        "        if len(hm_files[key][0]) == 1:\n",
        "            keys_to_pop.append(key)\n",
        "            count += 1\n",
        "\n",
        "    print(\"Before popping, number of keys to pop with length 1: \", count, \" and total length: \", len(hm_files.keys()))\n",
        "\n",
        "    for key in keys_to_pop:\n",
        "        hm_files.pop(key, None)\n",
        "\n",
        "    ## To check if the dictionary has any key with length 1\n",
        "    count = 0\n",
        "    for key in hm_files:\n",
        "        if len(hm_files[key][0]) == 1:\n",
        "            count += 1\n",
        "            # print(key)\n",
        "\n",
        "    print(\"After popping, number of keys to pop with length 1: \", count)\n",
        "    print(\"After popping, number of keys with length 2: \", len(hm_files.keys()))\n",
        "\n",
        "    return hm_files\n",
        "\n",
        "def loadFullImg(path, dsize):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in the path of a FULL image and loads it as a grayscale image (as\n",
        "    a numpy array with 3 channels).\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : {str}\n",
        "        The path of the FULL image.\n",
        "    Returns\n",
        "    -------\n",
        "    full_img : {numpy.ndarray}\n",
        "        The loaded image with shape = (self.target_size, self.target_size, 3)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # =====================================\n",
        "        #  2a. Read images (full)\n",
        "        # =====================================\n",
        "        # if not isinstance(path, str):\n",
        "        #     path = path.decode()\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(src=img, dsize=(dsize, dsize))\n",
        "\n",
        "        # Min max normalise to [0, 1].\n",
        "        norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "        # Stack grayscale image to make channels=3.\n",
        "        full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to loadFullImg!\\n{e}')\n",
        "        print((f\"Unable to loadFullImg!\\n{e}\"))\n",
        "\n",
        "    return full_img\n",
        "\n",
        "def loadMaskImg(path, dsize):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in the path of a MASK image and loads it as a grayscale image (as\n",
        "    a numpy array with 1 channel).\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : {str}\n",
        "        The path of the MASK image.\n",
        "    Returns\n",
        "    -------\n",
        "    full_img : {numpy.ndarray}\n",
        "        The loaded image with shape = (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # ========================\n",
        "        #  2b. Read images (mask)\n",
        "        # ========================\n",
        "        # if not isinstance(path, str):\n",
        "        #     path = path.decode()\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(src=img, dsize=(dsize,dsize))\n",
        "\n",
        "        # Min max normalise to [0, 1].\n",
        "        norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "        # Expand shape to (width, height, 1).\n",
        "        mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to loadMaskImg!\\n{e}')\n",
        "        print((f\"Unable to loadMaskImg!\\n{e}\"))\n",
        "\n",
        "    return mask_img\n",
        "\n",
        "def tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in a FULL image path and a MASK image path, loads the images using\n",
        "    loadFullImg() and loadMaskImg() and makes it TensorFlow executable.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x_path: {str}\n",
        "        The path of the FULL image to be loaded.\n",
        "    y_path: {str}\n",
        "        The path of the MASK image to be loaded.\n",
        "    Returns\n",
        "    -------\n",
        "    x : {tensor}\n",
        "        The FULL image loaded as a tensor with shape =\n",
        "        (self.target_size, self.target_size, 3)\n",
        "    y : {tensor}\n",
        "        The MASK image loaded as a tensor with shape =\n",
        "        (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def _parse(x_path, y_path):\n",
        "        x = loadFullImg(path=x_path, dsize=target_size)\n",
        "        y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "        return x, y\n",
        "\n",
        "    try:\n",
        "        # ===========\n",
        "        #  3. Parse\n",
        "        # ===========\n",
        "\n",
        "        # x_cc, y_cc = tf.numpy_function(_parse, [img_cc_path, mask_cc_path], [tf.float64, tf.float64])\n",
        "        # x_mlo, y_mlo = tf.numpy_function(_parse, [img_mlo_path, mask_mlo_path], [tf.float64, tf.float64])\n",
        "\n",
        "        x_cc, y_cc = _parse(img_cc_path, mask_cc_path)\n",
        "        x_mlo, y_mlo = _parse(img_mlo_path, mask_mlo_path)\n",
        "\n",
        "        print(np.shape(x_cc), np.shape(y_cc))\n",
        "\n",
        "        # x_cc.set_shape([target_size, target_size, 3])\n",
        "        # x_mlo.set_shape([target_size, target_size, 3])\n",
        "        # y_cc.set_shape([target_size, target_size, 1])\n",
        "        # y_mlo.set_shape([target_size, target_size, 1])\n",
        "\n",
        "        x = concatenate([x_cc, x_mlo], axis = -1)\n",
        "        y = concatenate([y_cc, y_mlo], axis = -1)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to tfParse!\\n{e}')\n",
        "        print((f\"Unable to tfParse!\\n{e}\"))\n",
        "\n",
        "def imgAugment(x_img, y_img):\n",
        "\n",
        "    \"\"\"\n",
        "    Apply random image augmentation to full mammogram scans (x_img). Note\n",
        "    that the same augmentation has to be applied to the masks (y_img), apart\n",
        "    from the brightness augmentation.\n",
        "    Parameters\n",
        "    ----------\n",
        "    x_img : {numpy.ndarray}\n",
        "        Full mammogram scan to augment.\n",
        "    y_img : {numpy.ndarray}\n",
        "        Corresponding mask of `x_img`.\n",
        "    Returns\n",
        "    -------\n",
        "    x_img : {numpy.ndarray}\n",
        "        Augmented x_img.\n",
        "    y_img : {numpy.ndarray}\n",
        "        Augmented y_img.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # =========\n",
        "        #  LR Flip\n",
        "        # =========\n",
        "        # Generate random number from uniform distribution\n",
        "        # in the range [0.0, 1.0)\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            x_img = tf.image.flip_left_right(image=x_img)\n",
        "            y_img = tf.image.flip_left_right(image=y_img)\n",
        "\n",
        "        # =========\n",
        "        #  UD Flip\n",
        "        # =========\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            x_img = tf.image.flip_up_down(image=x_img)\n",
        "            y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "        # ============\n",
        "        #  Brightness\n",
        "        # ============\n",
        "        # Only change the brightness of x_img, not y_img!\n",
        "        x_img = tf.image.random_brightness(\n",
        "            image=x_img, max_delta= brightness_delta\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to imgAugment!\\n{e}')\n",
        "        print((f\"Unable to imgAugment!\\n{e}\"))\n",
        "\n",
        "    return x_img, y_img\n",
        "\n",
        "def makeTFDataset(shuffle, augment, x_paths_list, y_paths_list, batch_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Takes in a FULL image path and a MASK image path, loads the images using\n",
        "    loadFullImg() and loadMaskImg() and makes it TensorFlow executable.\n",
        "    Parameters\n",
        "    ----------\n",
        "    shuffle : {boolean}\n",
        "        If True, shuffle dataset. Should only shuffle train set.\n",
        "    augment : {boolean}\n",
        "        If True, perform augmentation. Should only augment test set.\n",
        "    x_paths_list : {list}\n",
        "        The path of the FULL image to be loaded.\n",
        "    y_paths_list : {list}\n",
        "        The path of the MASK image to be loaded.\n",
        "    batch_size : {int}\n",
        "        The batch size to create the dataset with.\n",
        "    Returns\n",
        "    -------\n",
        "    ds : {RepeatDataset}\n",
        "        The dataset with x (FULL) and y (MASK) images loaded from\n",
        "        `x_paths_list` and `y_paths_list`.\n",
        "        For each `batch` in `ds`:\n",
        "        - type = tuple\n",
        "        - len = 2\n",
        "        - `batch[0]` (this is a batch of the FULL images):\n",
        "            - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "            - shape = (self.batch_size, self.target_size, self.target_size, 3)\n",
        "            - `batch[0][0]` (this is the first FULL image in the batch):\n",
        "                - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "                - shape = (self.target_size, self.target_size, 3)\n",
        "        - `batch[1]` (this is a batch the MASK images):\n",
        "            - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "            - shape = (self.batch_size, self.target_size, self.target_size, 1)\n",
        "                - `batch[1][0]` (this is the first MASK image in the batch):\n",
        "                - type = tensorflow.python.fraework.ops.EagerTensor\n",
        "                - shape = (self.target_size, self.target_size, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # ====================\n",
        "        #  4. Make TF Dataset\n",
        "        # ====================\n",
        "\n",
        "        ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "\n",
        "        # Shuffle the paths of the elements\n",
        "        # with buffer_size=len(x_paths_list), since storing all the paths\n",
        "        # in memory will not be an issue (as compared to storing all the\n",
        "        # imported images as tensors).\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "        # Transform paths to images after shuffling the paths.\n",
        "        ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        # Apply image augmentation.\n",
        "        if augment:\n",
        "            ds = ds.map(\n",
        "                imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "            )\n",
        "\n",
        "        # Batch only AFTER shuffle, so that we shuffled the elements not the batches.\n",
        "        ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "        ds = ds.repeat()  # We need to repeat in order to train for > 1 epoch.\n",
        "\n",
        "    except Exception as e:\n",
        "        # logger.error(f'Unable to makeTFDataset!\\n{e}')\n",
        "        print((f\"Unable to makeTFDataset!\\n{e}\"))\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hm_train_files_multi_view = create_dict(train_full_dir, train_mask_combined_dir)\n",
        "hm_test_files_multi_view = create_dict(test_full_dir, test_mask_combined_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd5QpS-lj1-s",
        "outputId": "a24975a8-a5dc-49bb-b5c8-f0343b7d3638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before popping, number of keys to pop with length 1:  213  and total length:  722\n",
            "After popping, number of keys to pop with length 1:  0\n",
            "After popping, number of keys with length 2:  509\n",
            "Before popping, number of keys to pop with length 1:  59  and total length:  211\n",
            "After popping, number of keys to pop with length 1:  0\n",
            "After popping, number of keys with length 2:  152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = [], []\n",
        "\n",
        "for key in hm_train_files_multi_view:\n",
        "    img_cc_path, img_mlo_path = sorted(hm_train_files_multi_view[key][0])\n",
        "    mask_cc_path, mask_mlo_path = sorted(hm_train_files_multi_view[key][1])\n",
        "\n",
        "    x, y = tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path)\n",
        "    X_train.append(x)\n",
        "    y_train.append(y)"
      ],
      "metadata": {
        "id": "M-WDWdA4kPxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = [], []\n",
        "\n",
        "for key in hm_test_files_multi_view:\n",
        "    img_cc_path, img_mlo_path = sorted(hm_test_files_multi_view[key][0])\n",
        "    mask_cc_path, mask_mlo_path = sorted(hm_test_files_multi_view[key][1])\n",
        "\n",
        "    x, y = tfParse(img_cc_path, img_mlo_path, mask_cc_path, mask_mlo_path)\n",
        "    X_test.append(x)\n",
        "    y_test.append(y)"
      ],
      "metadata": {
        "id": "CjhfpsiHwesE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIumkaRWj7t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating tf dataset"
      ],
      "metadata": {
        "id": "a5s7PuM1j-qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = int(len(X_train) * 0.2)\n",
        "train_size = len(X_train) - val_size"
      ],
      "metadata": {
        "id": "T3gZiQu5b945"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_whole = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "\n",
        "train_ds = train_ds_whole.take(train_size)\n",
        "val_ds = train_ds_whole.skip(train_size).take(val_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "metadata": {
        "id": "cQ6jel1XVAkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train size: \", len(train_ds))\n",
        "print(\"Val size: \", len(val_ds))\n",
        "print(\"Test size: \", len(test_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77tFQ0T3c_kK",
        "outputId": "9f069c5a-0379-4cb3-e1d1-af07997e0ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:  408\n",
            "Val size:  101\n",
            "Test size:  152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.shuffle(train_size).batch(batch_size)\n",
        "val_ds = val_ds.shuffle(val_size).batch(batch_size)\n",
        "\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "WAGLVA49VZPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxfSTtLSwepc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6kgTMGcqHRE"
      },
      "source": [
        "## **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP-NZHkzqGSE"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    \n",
        "# def dice(pred, true, k = 1):\n",
        "#     intersection = np.sum(pred[true==k]) * 2.0\n",
        "#     dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "#     return dice\n",
        "\n",
        "# def iou(pred, true, k = 1):\n",
        "#     intersection = np.sum(pred[true==k])\n",
        "#     iou = intersection / (np.sum(pred) + np.sum(true) - intersection)\n",
        "#     return iou\n",
        "\n",
        "# def iou_coef(y_true, y_pred, smooth=1):\n",
        "#   intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "#   union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "#   iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "#   return iou\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def sens(y_true, y_pred):\n",
        "    num=K.sum(K.multiply(y_true, y_pred))\n",
        "    denom=K.sum(y_true)\n",
        "    if denom==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return  num/denom\n",
        "\n",
        "def spec(y_true, y_pred):\n",
        "    num=K.sum(K.multiply(y_true==0, y_pred==0))\n",
        "    denom=K.sum(y_true==0)\n",
        "    if denom==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return  num/denom\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "\n",
        "## From TDS guy\n",
        "\n",
        "def iouMetric(y_true, y_pred):\n",
        "\n",
        "      \"\"\"\n",
        "      Calculates the intersection-over-union between a ground truth mask and\n",
        "      the corresponding predicted mask from the model.\n",
        "      Parameters\n",
        "      ----------\n",
        "      y_true : {tf.Tensor}\n",
        "          The ground truth mask.\n",
        "      y_pred : {tf.Tensor}\n",
        "          Corresponding predicted mask.\n",
        "      Returns\n",
        "      -------\n",
        "      compute_iou() : {tf.numpy_function}\n",
        "          A function that calculates the IOU metric.\n",
        "      \"\"\"\n",
        "\n",
        "      try:\n",
        "\n",
        "          def compute_iou(y_true, y_pred):\n",
        "              intersection = (y_true * y_pred).sum()\n",
        "              union = y_true.sum() + y_pred.sum() - intersection\n",
        "              x = (intersection + 1e-15) / (union + 1e-15)\n",
        "              x = x.astype(np.float32)\n",
        "              return x\n",
        "\n",
        "          return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "\n",
        "      except Exception as e:\n",
        "          # logger.error(f'Unable to iouMetric!\\n{e}')\n",
        "          print((f\"Unable to iouMetric!\\n{e}\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsqvnOJB3IWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8driqnr2Eo5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CvAM with Basic U-Net**"
      ],
      "metadata": {
        "id": "-hRwWO5K43vN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Architecture1.png](https://i.imgur.com/YeZ3KPH.png)"
      ],
      "metadata": {
        "id": "YASzhejWDyT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JeycCV5oEPVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cvam_spatial_attention(x_cc,x_mlo):\n",
        "    avg_pool_cc = tf.reduce_mean(x_cc, axis= [3], keepdims= True)\n",
        "    max_pool_cc = tf.reduce_max(x_cc, axis=[3], keepdims=True)\n",
        "\n",
        "    avg_pool_mlo = tf.reduce_mean(x_mlo, axis= [3], keepdims= True)\n",
        "    max_pool_mlo = tf.reduce_max(x_mlo, axis=[3], keepdims=True)\n",
        "\n",
        "    concat = concatenate([avg_pool_cc, max_pool_cc, avg_pool_mlo, max_pool_mlo], axis = -1)\n",
        "    cvam_spatial_feature = Conv2D(4, (3, 3), padding=\"same\")(concat)\n",
        "    cvam_spatial_feature = Activation('relu')(cvam_spatial_feature)\n",
        "    cvam_spatial_feature = Conv2D(1, (3, 3), padding=\"same\")(cvam_spatial_feature)\n",
        "    cvam_spatial_feature = Activation('sigmoid')(cvam_spatial_feature)\n",
        "\n",
        "    x_cvam_cc_spatial, x_cvam_mlo_spatial = Multiply()([x_cc, cvam_spatial_feature]), Multiply()([x_mlo, cvam_spatial_feature])\n",
        "    return x_cvam_cc_spatial, x_cvam_mlo_spatial"
      ],
      "metadata": {
        "id": "qkD7bKWiF11s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cvam_channel_attention(x_cc, x_mlo, ratio=8):\n",
        "    features=[x_cc, x_mlo]\n",
        "    channel = x_cc.shape[-1]\t\n",
        "    shared_layer_one = Dense(channel//ratio,\n",
        "                activation='relu',\n",
        "                kernel_initializer='he_normal',\n",
        "                use_bias=True,\n",
        "                bias_initializer='zeros')\n",
        "    shared_layer_two = Dense(channel,\n",
        "                kernel_initializer='he_normal',\n",
        "                use_bias=True,\n",
        "                bias_initializer='zeros')\n",
        "\n",
        "    avg_pool_cc = tf.reduce_mean(x_cc, axis= [-2, -3], keepdims= True)\n",
        "    avg_pool_cc = shared_layer_one(avg_pool_cc)\n",
        "    avg_pool_cc = shared_layer_two(avg_pool_cc)\n",
        "\n",
        "    max_pool_cc = tf.reduce_max(x_cc, axis= [-2, -3], keepdims= True)\n",
        "    max_pool_cc = shared_layer_one(max_pool_cc)\n",
        "    max_pool_cc = shared_layer_two(max_pool_cc)\n",
        "\n",
        "    avg_pool_mlo = tf.reduce_mean(x_mlo, axis= [-2, -3], keepdims= True)\n",
        "    avg_pool_mlo = shared_layer_one(avg_pool_mlo)\n",
        "    avg_pool_mlo = shared_layer_two(avg_pool_mlo)\n",
        "\n",
        "    max_pool_mlo = tf.reduce_max(x_mlo, axis= [-2, -3], keepdims= True)\n",
        "    max_pool_mlo = shared_layer_one(max_pool_mlo)\n",
        "    max_pool_mlo = shared_layer_two(max_pool_mlo)\n",
        "\n",
        "    concat = concatenate([avg_pool_cc, max_pool_cc, avg_pool_mlo, max_pool_mlo], axis= -1)\n",
        "    cvam_channel_feature = Dense(x_cc.shape[-1])(concat)\n",
        "    cvam_channel_feature = Activation('sigmoid')(cvam_channel_feature)\n",
        "    x_cvam_cc_channel, x_cvam_mlo_channel = Multiply()([x_cc, cvam_channel_feature]), Multiply()([x_mlo, cvam_channel_feature])\n",
        "    \n",
        "    return x_cvam_cc_channel, x_cvam_mlo_channel"
      ],
      "metadata": {
        "id": "9mQLXFsP7OoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some possible issues:\n",
        "\n",
        "\n",
        "*   CvAM Channel and Spatial attention uses axis = 3\n",
        "*   CBAM paper mentions 1 hidden layer for channel attention\n",
        "\n"
      ],
      "metadata": {
        "id": "kly_h1mx-Hw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cvamBlock(x_cc, x_mlo, ratio = 8):\n",
        "    ## First goes through channel attention\n",
        "    x_cc, x_mlo = cvam_channel_attention(x_cc, x_mlo)\n",
        "    ## Second goes through spatial attention\n",
        "    x_cc, x_mlo = cvam_spatial_attention(x_cc, x_mlo)\n",
        "\n",
        "    return x_cc, x_mlo"
      ],
      "metadata": {
        "id": "OY3WVgox_D9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3yG4h2AsUbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![UNet-with-CvAM](https://i.imgur.com/XFKEWBB.png)"
      ],
      "metadata": {
        "id": "0B6W7JxKHEEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_with_cvam():\n",
        "    inputs = Input((target_size, target_size, 6))\n",
        "\n",
        "    ## Splitting the inputs into cc and mlo\n",
        "\n",
        "    input_cc = inputs[:, :, :, : 3]\n",
        "    input_mlo = inputs[:, :, :, 3 :]\n",
        "\n",
        "    ## 1st Layer\n",
        "\n",
        "    conv1_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(input_cc)\n",
        "    conv1_cc = BatchNormalization()(conv1_cc)\n",
        "    conv1_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1_cc)\n",
        "    conv1_cc = BatchNormalization()(conv1_cc)\n",
        "\n",
        "    conv1_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(input_mlo)\n",
        "    conv1_mlo = BatchNormalization()(conv1_mlo)\n",
        "    conv1_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1_mlo)\n",
        "    conv1_mlo = BatchNormalization()(conv1_mlo)\n",
        "\n",
        "    pool1_cc = MaxPooling2D((2,2), padding='same')(conv1_cc)\n",
        "    pool1_mlo = MaxPooling2D((2,2), padding='same')(conv1_mlo)\n",
        "\n",
        "    ## 2nd Layer\n",
        "\n",
        "    conv2_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1_cc)\n",
        "    conv2_cc = BatchNormalization()(conv2_cc)\n",
        "    conv2_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2_cc)\n",
        "    conv2_cc = BatchNormalization()(conv2_cc)\n",
        "\n",
        "    conv2_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1_mlo)\n",
        "    conv2_mlo = BatchNormalization()(conv2_mlo)\n",
        "    conv2_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2_mlo)\n",
        "    conv2_mlo = BatchNormalization()(conv2_mlo)\n",
        "\n",
        "    conv2_cc, conv2_mlo = cvamBlock(conv2_cc, conv2_mlo)\n",
        "\n",
        "    pool2_cc = MaxPooling2D((2,2), padding='same')(conv2_cc)\n",
        "    pool2_mlo = MaxPooling2D((2,2), padding='same')(conv2_mlo)\n",
        "\n",
        "    ## 3rd Layer\n",
        "\n",
        "    conv3_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2_cc)\n",
        "    conv3_cc = BatchNormalization()(conv3_cc)\n",
        "    conv3_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3_cc)\n",
        "    conv3_cc = BatchNormalization()(conv3_cc)\n",
        "\n",
        "    conv3_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2_mlo)\n",
        "    conv3_mlo = BatchNormalization()(conv3_mlo)\n",
        "    conv3_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3_mlo)\n",
        "    conv3_mlo = BatchNormalization()(conv3_mlo)\n",
        "\n",
        "    conv3_cc, conv3_mlo = cvamBlock(conv3_cc, conv3_mlo)\n",
        "\n",
        "    pool3_cc = MaxPooling2D((2,2), padding='same')(conv3_cc)\n",
        "    pool3_mlo = MaxPooling2D((2,2), padding='same')(conv3_mlo)\n",
        "\n",
        "\n",
        "    ## 4th Layer\n",
        "\n",
        "    conv4_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3_cc)\n",
        "    conv4_cc = BatchNormalization()(conv4_cc)\n",
        "    conv4_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4_cc)\n",
        "    conv4_cc = BatchNormalization()(conv4_cc)\n",
        "\n",
        "    conv4_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3_mlo)\n",
        "    conv4_mlo = BatchNormalization()(conv4_mlo)\n",
        "    conv4_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4_mlo)\n",
        "    conv4_mlo = BatchNormalization()(conv4_mlo)\n",
        "\n",
        "    conv4_cc, conv4_mlo = cvamBlock(conv4_cc, conv4_mlo)\n",
        "\n",
        "    pool4_cc = MaxPooling2D((2,2), padding='same')(conv4_cc)\n",
        "    pool4_mlo = MaxPooling2D((2,2), padding='same')(conv4_mlo)\n",
        "\n",
        "    ## 5th Layer\n",
        "\n",
        "    conv5_cc = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4_cc)\n",
        "    conv5_cc = BatchNormalization()(conv5_cc)\n",
        "    conv5_cc = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_cc)\n",
        "    conv5_cc = BatchNormalization()(conv5_cc)\n",
        "\n",
        "    conv5_mlo = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4_mlo)\n",
        "    conv5_mlo = BatchNormalization()(conv5_mlo)\n",
        "    conv5_mlo = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5_mlo)\n",
        "    conv5_mlo = BatchNormalization()(conv5_mlo)\n",
        "\n",
        "    ## 6th Layer\n",
        "\n",
        "    up6_cc = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5_cc), conv4_cc], axis=3)\n",
        "    conv6_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(up6_cc)\n",
        "    conv6_cc = BatchNormalization()(conv6_cc)\n",
        "    conv6_cc = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6_cc)\n",
        "    conv6_cc = BatchNormalization()(conv6_cc)\n",
        "\n",
        "    up6_mlo = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5_mlo), conv4_mlo], axis=3)\n",
        "    conv6_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(up6_mlo)\n",
        "    conv6_mlo = BatchNormalization()(conv6_mlo)\n",
        "    conv6_mlo = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6_mlo)\n",
        "    conv6_mlo = BatchNormalization()(conv6_mlo)\n",
        "\n",
        "    conv6_cc, conv6_mlo = cvamBlock(conv6_cc, conv6_mlo)\n",
        "\n",
        "    ## 7th Layer\n",
        "    \n",
        "    up7_cc = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6_cc), conv3_cc], axis=3)\n",
        "    conv7_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(up7_cc)\n",
        "    conv7_cc = BatchNormalization()(conv7_cc)\n",
        "    conv7_cc = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7_cc)\n",
        "    conv7_cc = BatchNormalization()(conv7_cc)\n",
        "\n",
        "    up7_mlo = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6_mlo), conv3_mlo], axis=3)\n",
        "    conv7_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(up7_mlo)\n",
        "    conv7_mlo = BatchNormalization()(conv7_mlo)\n",
        "    conv7_mlo = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7_mlo)\n",
        "    conv7_mlo = BatchNormalization()(conv7_mlo)\n",
        "\n",
        "    conv7_cc, conv7_mlo = cvamBlock(conv7_cc, conv7_mlo)\n",
        "\n",
        "    ## 8th Layer\n",
        "\n",
        "    up8_cc = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7_cc), conv2_cc], axis=3)\n",
        "    conv8_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(up8_cc)\n",
        "    conv8_cc = BatchNormalization()(conv8_cc)\n",
        "    conv8_cc = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8_cc)\n",
        "    conv8_cc = BatchNormalization()(conv8_cc)\n",
        "\n",
        "    up8_mlo = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7_mlo), conv2_mlo], axis=3)\n",
        "    conv8_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(up8_mlo)\n",
        "    conv8_mlo = BatchNormalization()(conv8_mlo)\n",
        "    conv8_mlo = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8_mlo)\n",
        "    conv8_mlo = BatchNormalization()(conv8_mlo)\n",
        "\n",
        "    conv8_cc, conv8_mlo = cvamBlock(conv8_cc, conv8_mlo)\n",
        "\n",
        "    ## 9th Layer\n",
        "    \n",
        "    up9_cc = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8_cc), conv1_cc], axis=3)\n",
        "    conv9_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(up9_cc)\n",
        "    conv9_cc = BatchNormalization()(conv9_cc)\n",
        "    conv9_cc = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9_cc)\n",
        "    conv9_cc = BatchNormalization()(conv9_cc)\n",
        "\n",
        "    up9_mlo = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8_mlo), conv1_mlo], axis=3)\n",
        "    conv9_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(up9_mlo)\n",
        "    conv9_mlo = BatchNormalization()(conv9_mlo)\n",
        "    conv9_mlo = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9_mlo)\n",
        "    conv9_mlo = BatchNormalization()(conv9_mlo)\n",
        "\n",
        "    ## Final Layer\n",
        "        \n",
        "    conv10_cc = Conv2D(1, (1, 1), activation='sigmoid')(conv9_cc)\n",
        "    conv10_mlo = Conv2D(1, (1, 1), activation='sigmoid')(conv9_mlo)\n",
        "\n",
        "    ## Stacking the final masks on top of another\n",
        "    conv10 = concatenate([conv10_cc, conv10_mlo], axis= -1)\n",
        "\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "    model.compile(optimizer = Adam(1e-3), loss = 'binary_crossentropy', metrics = [dice_coef, jacard, 'accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "yBKG_rMUsUYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_cvam = unet_with_cvam()"
      ],
      "metadata": {
        "id": "eqBG93mFTUQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDz5599HVAh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = unet_cvam.fit(train_ds,\n",
        "                    validation_data= val_ds,\n",
        "                    epochs= 3,\n",
        "                    batch_size = batch_size,\n",
        "                    verbose= 1\n",
        "                )   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddisOmMswwwi",
        "outputId": "7ffd2d17-74e7-42a2-8577-fea23eb5d4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.1422 - dice_coef: 0.0154 - jacard: 0.0078 - accuracy: 0.2460 - val_loss: 0.1066 - val_dice_coef: 0.0068 - val_jacard: 0.0034 - val_accuracy: 0.7173\n",
            "Epoch 2/3\n",
            "51/51 [==============================] - 5s 102ms/step - loss: 0.0872 - dice_coef: 0.0215 - jacard: 0.0109 - accuracy: 0.2717 - val_loss: 0.0753 - val_dice_coef: 0.0066 - val_jacard: 0.0033 - val_accuracy: 0.0277\n",
            "Epoch 3/3\n",
            "51/51 [==============================] - 5s 101ms/step - loss: 0.0595 - dice_coef: 0.0281 - jacard: 0.0143 - accuracy: 0.3119 - val_loss: 0.0508 - val_dice_coef: 0.0108 - val_jacard: 0.0054 - val_accuracy: 0.0173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaGnHz_hxNR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_cvam.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "bEZpz24CxNPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730b964f-e3f2-432f-f790-be6ccea303e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 34ms/step - loss: 0.0532 - dice_coef: 0.0084 - jacard: 0.0042 - accuracy: 0.0172\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0531751923263073,\n",
              " 0.008363294415175915,\n",
              " 0.004188459366559982,\n",
              " 0.017197884619235992]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHHJjdJowwt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzOvGpgJ43Tj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}